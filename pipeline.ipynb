{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import kfp\n",
    "import kfp.components as comp\n",
    "import kfp.dsl as dsl\n",
    "import kfp.v2.dsl\n",
    "\n",
    "import kfp_tekton\n",
    "from kfp_tekton import k8s_client_helper\n",
    "\n",
    "from kubernetes.client.models import V1EnvVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME = \"tf_spacenet_cv_classify_pipeline-e429392\"\n",
    "PIPELINE_PACKAGE = f\"{PIPELINE_NAME}.zip\"\n",
    "EXPERIMENT_NAME = \"RMS ET Intern Project\"\n",
    "PERSISTENT_VOLUME_CLAIM_NAME = \"rms-et-sn-pvc\"\n",
    "\n",
    "KUBEFLOW_PUBLIC_ENDPOINT_URL = \"https://kubeflow.apps.pcell.ai.us.lmco.com\"\n",
    "SESSION_COOKIE = \"authservice_session=MTY1OTM0OTEyMHxOd3dBTkRRMU1reEtTMEpIUXpaUk1rRkRUa2RFVDFOTVZGSTFVbEkxVlZVelVVRllSa2MxVmtkUVIxbGFXRkZSVnpkWVdqTktRMUU9fBfxSNxN_ndIjq1W6xrapQH6_4UJ-WjXbgUMduHz-oEq\"\n",
    "KUBEFLOW_PROFILE_NAME = \"kf-rms-et-intern-project-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.component\n",
    "def view_data():\n",
    "    import json\n",
    "    import os\n",
    "    import logging\n",
    "    DATASET_PATH = \"/data/V1/sn1_AOI_1_RIO/sn1_AOI_1_RIO/sn1_AOI_1_RIO/\"\n",
    "\n",
    "    PATH_TO_COLLECTION_FILE = os.path.join(DATASET_PATH, 'collection.json')\n",
    "\n",
    "    with open(PATH_TO_COLLECTION_FILE, 'r') as f:\n",
    "        collection_json = json.load(f)\n",
    "\n",
    "    print(f\"collection_json top level keys: {collection_json.keys()}\\n\")\n",
    "    print(f\"description: {collection_json['description']}\")\n",
    "    \n",
    "    def limit_string(s, chars=200):\n",
    "        s = str(s)\n",
    "        len_to_print = max(min(len(s), chars), 1)\n",
    "        return s[0:len_to_print]\n",
    "    [print(f\"{k} : {limit_string(collection_json[k])}\") for k in collection_json.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_data_op = comp.func_to_container_op(view_data, base_image=\"harbor.ai.us.lmco.com/ai-factory-local/internal/aws-cli:1.20.58-debian-10-r2-0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Step 2##\n",
    "@kfp.dsl.component\n",
    "def predict():\n",
    "    import datetime\n",
    "    import json\n",
    "    import os\n",
    "    import math\n",
    "    import random\n",
    "    \n",
    "    # for dataset\n",
    "    import torch\n",
    "    import numpy as np\n",
    "\n",
    "    # Python Image Library can \n",
    "    # load tiffs and convert to numpy arrays\n",
    "    from PIL import Image\n",
    "    from IPython.display import display\n",
    "\n",
    "    # for mask creation based on geospatial data\n",
    "    import fiona\n",
    "    import rioxarray\n",
    "    import geojson\n",
    "\n",
    "    from pathlib import Path\n",
    "    # import UNet Model Configuration, UNet Vision Model Configuration, and the Vision Model\n",
    "    import classification as lmclassification\n",
    "    from classification.data_types.network_callbacks.checkpoint_callback import CheckPointCallback as CheckpointCallback\n",
    "    from classification.network_models.configurations.unet_model_configuration import UNetModelConfiguration as ModelConfiguration\n",
    "    from classification.vision.models.configurations.unet_vision_model_configuration import UNetVisionModelConfiguration as VisionModelConfiguration\n",
    "    from classification.vision.models.unet_vision_model import UNetVisionModel as Model\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.patches as patches\n",
    "    import matplotlib.colors as colors\n",
    "    \n",
    "    class SpaceNetDataset(torch.utils.data.Dataset):\n",
    "        \"\"\"\n",
    "        A torch.utils.data.Dataset wrapping the SpaceNet Building Detection V1 dataset\n",
    "        \"\"\"\n",
    "\n",
    "        def __init__(self, path_to_collection, *args, **kwargs):\n",
    "            \"\"\"\n",
    "            Construct the dataset\n",
    "\n",
    "            Provide any information required to allow subsequent operation\n",
    "            \"\"\"\n",
    "\n",
    "            if not isinstance(path_to_collection, Path):\n",
    "                path_to_collection = Path(path_to_collection)\n",
    "\n",
    "            self.path_to_collection = path_to_collection\n",
    "            self.collection_dir = os.path.dirname(path_to_collection)\n",
    "\n",
    "            with open(self.path_to_collection, 'r') as f:\n",
    "                self.collection = json.load(f)        \n",
    "\n",
    "            # self.links holds all the top level folders\n",
    "            # filter out the ones that end with -labels since we know \n",
    "            # there will be a corresponding non-labels folder\n",
    "            self.links = [x[\"href\"] for x in self.collection[\"links\"] if not os.path.dirname(x[\"href\"]).endswith('-labels') ]\n",
    "\n",
    "        def __len__(self) -> int:\n",
    "            \"\"\"\n",
    "            Returns:\n",
    "                The length of the whole dataset to load\n",
    "            \"\"\"\n",
    "            return len(self.links)\n",
    "\n",
    "        def __getitem__(self, idx) -> Tuple[np.ndarray, Dict[str, np.ndarray]]:        \n",
    "            \"\"\"\n",
    "            Given an index, provide the training example at that index\n",
    "\n",
    "            To satisfy the CCM return a tuple of 2 elements:\n",
    "                The first element is a numpy np.ndarray, 32-bit or 64-bit float, with shape (channels, pixel height, pixel width)\n",
    "                The second element is a dictionary.\n",
    "                    The only required key is 'masks'\n",
    "                    The 'masks' key must map to a numpy np.ndarray, 64-bit integers, with shape (classes, pixel height, pixel width)\n",
    "                    In this case the classes are background and building (just 2 classes)\n",
    "                    For the background class, pixel locations that are background should be set to 1, otherwise 0\n",
    "                    For the building class, pixel locations that are buildings should be set to 1, otherwise 0\n",
    "                    Image values in the numpy ndarray should be normalized to a range from 0.0 to 1.0\n",
    "\n",
    "            Other requirements:\n",
    "                Image Width must be the same as Segmentation Mask Width\n",
    "                Image Height must be the same as Segmentation Mask Height\n",
    "\n",
    "                If no features are present. the mask should still exist but take on default values, eg\n",
    "                    background class all ones\n",
    "                    building class all zeros\n",
    "                    other constraints are still enforced\n",
    "\n",
    "            Args:\n",
    "                index into the dataset to sample\n",
    "\n",
    "            Returns:\n",
    "                The dataset example at a given index in the form of a tuple of\n",
    "                np.ndarray and dictionary of string key mapped to np.ndarrays\n",
    "            \"\"\"\n",
    "\n",
    "            # index into folders (in the indexed folder with main files)\n",
    "            folder = self.links[idx]\n",
    "            \n",
    "            # construct the known corresponding label folder name (will look like 'sn1_AOI_1_RIO_img1033-labels')\n",
    "            folder_name =  os.path.dirname(folder)\n",
    "            label_folder_name = folder_name + '-labels'\n",
    "\n",
    "            # construct the relative path to the \"stac.json file\"\n",
    "            folder_json_path = os.path.join(folder_name, 'stac.json')\n",
    "            label_json_path = os.path.join(label_folder_name, 'stac.json')\n",
    "\n",
    "            # construct the path to the image file -- stored in assets.RGB. in stac.json (img)\n",
    "            #img_path = os.path.join(json_path, 'assets.RGB')\n",
    "            test = os.path.join(DATASET_PATH, folder_json_path)\n",
    "            with open(test, 'r') as igj:\n",
    "                data = json.load(igj)            \n",
    "            img_name = data[\"assets\"][\"RGB\"][\"href\"]\n",
    "            img_path = os.path.join(DATASET_PATH, folder_name, img_name)\n",
    "\n",
    "            # construct the paths to the labels file -- stored in assets.labels.href in stac.json (label)\n",
    "            test = os.path.join(DATASET_PATH, label_json_path)\n",
    "            with open(test, 'r') as igj:\n",
    "                data = json.load(igj)            \n",
    "            label_name = data[\"assets\"][\"labels\"][\"href\"]\n",
    "            label_path = os.path.join(DATASET_PATH, label_folder_name, label_name)\n",
    "\n",
    "            # open the .tif image from disk using PIL.Image\n",
    "            img = Image.open(img_path)\n",
    "            \n",
    "            # convert the PIL image to a numpy array - this will be returned\n",
    "            img_arr = np.array(img, dtype='float64')\n",
    "            \n",
    "            # normalize from 0.0 to 1.0\n",
    "            img = np.array(img_arr / np.linalg.norm(img_arr))\n",
    "\n",
    "            # open with fiona to get features for mask - this represnts the buildings\n",
    "            with fiona.open(label_path, 'r') as f:\n",
    "                features = [feature[\"geometry\"] for feature in f]\n",
    "                \n",
    "            # create the rasterizer object based on the image data using rioxarray\n",
    "            rds = rioxarray.open_rasterio(img_path).isel(band=0)\n",
    "\n",
    "            # get the geojson data from the label file                \n",
    "            with open(label_path) as igj:\n",
    "                data = geojson.load(igj)\n",
    "                \n",
    "            print(f\"labels data = {data}\")\n",
    "\n",
    "\n",
    "            # binary crossentropy requires you to create masks of shape (2, height, width)\n",
    "            # the first channel represnts classes; 0=background, 1=building\n",
    "            mask = np.zeros((2, *img.shape[0:2])).astype(np.int64)\n",
    "            mask[0,:,:] = np.ones((1, *img.shape[0:2])) # background by default\n",
    "\n",
    "            # now if this training/validation example has features (building masks)\n",
    "            if len(features) > 0:\n",
    "\n",
    "                # get the mask - binary cross entropy:\n",
    "                # clip the image to remove the background using rastersizer_object.rio.clip\n",
    "                # ex. rds.rio.clip(features_array, geojson_data[\"crs\"][\"properties\"][\"name\"], drop=False)\n",
    "                rds = rds.rio.clip(features, data[\"crs\"][\"properties\"][\"name\"], drop=False)\n",
    "\n",
    "                # convert to np array\n",
    "                nprds = np.array(rds)\n",
    "\n",
    "                # search your clipped image for values greater than .5\n",
    "                # if greater, return the corresponding class (0 or 1) and store that value \n",
    "                # in the first channel of your mask\n",
    "                mask[0, :, :] = np.where((nprds)>0.5, 0, mask[0, :, :])\n",
    "                mask[1, :, :] = np.where(nprds>0.5, 1, mask[1, :, :])\n",
    "\n",
    "            # if the example did not have features, leave the images and masks as they were\n",
    "            # channels, height, width\n",
    "\n",
    "            # clip both masks and images to ensure they are the same size\n",
    "            # otherwise CCM / Most Conv networks will not accept\n",
    "            #print('img row:', np.size(img, axis=0), 'img col:', np.size(img, axis=1), 'img tall:', np.size(img, axis=2))\n",
    "            #print('img row:', np.size(mask, axis=0), 'img col:', np.size(mask, axis=1), 'img tall:', np.size(mask, axis=2))\n",
    "            \n",
    "            img = np.transpose(img,(2,0,1))\n",
    "            min0 = min((np.size(img, axis=0)),(np.size(mask, axis=0)))\n",
    "            min1 = min((np.size(img, axis=1)),(np.size(mask, axis=1)))\n",
    "            min2 = min((np.size(img, axis=2)),(np.size(mask, axis=2)))           \n",
    "            \n",
    "            mask = np.resize(mask, (min0,min1,min2))\n",
    "            image = np.resize(img, (min0,min1,min2))\n",
    "            \n",
    "            #print('img row:', np.size(mask, axis=0), 'img col:', np.size(mask, axis=1), 'img tall:', np.size(mask, axis=2))\n",
    "            #print('img row:', np.size(image, axis=0), 'img col:', np.size(image, axis=1), 'img tall:', np.size(image, axis=2))\n",
    "            \n",
    "            # CCM vision models expect targets to be in a dictionary \n",
    "            # other keys for other types of computer vision problems include\n",
    "            # 'boxes' and 'labels'. UNet does not require those\n",
    "            return image, {'masks': mask}\n",
    "        \n",
    "    # Instantiate the DataLoader\n",
    "    DATASET_PATH = \\\n",
    "    \"\"\"/data/V1/sn1_AOI_1_RIO/sn1_AOI_1_RIO/sn1_AOI_1_RIO/\"\"\"\n",
    "    PATH_TO_COLLECTION_FILE=os.path.join(DATASET_PATH, 'collection.json')\n",
    "    dataset = SpaceNetDataset(PATH_TO_COLLECTION_FILE)\n",
    "\n",
    "    TRAIN_SPLIT = 0.7\n",
    "    TEST_SPLIT = 0.3\n",
    "\n",
    "    test_dataset, train_dataset = torch.utils.data.random_split(\n",
    "        dataset, \n",
    "        [math.floor(TEST_SPLIT*len(dataset)), math.ceil(TRAIN_SPLIT*len(dataset)) ],\n",
    "        generator=torch.Generator().manual_seed(1234)\n",
    "    )\n",
    "\n",
    "    # instantiate UNet Model Configuration\n",
    "    layers_config = ModelConfiguration()\n",
    "    \n",
    "    # instantiate UNet Vision Model Configuration    \n",
    "    # ensure we allow for the background class and building class RGB #input_channels = 3 is addition from QA\n",
    "    #Answer below found in unet_vision_model_example  from vision folder from link below\n",
    "    model_config = VisionModelConfiguration(input_shape=(480, 480), n_classes=4, input_channels=3, layers_model_configuration=layers_config,\n",
    "                                            training_epochs=2, validation_split=0.0, learning_rate=0.0001, batch_size=5)\n",
    "\n",
    "    # during testing x% of the training dataset will be reserved for validation\n",
    "\n",
    "\n",
    "    # Instantiate UNet\n",
    "    unet_model = Model(model_config)\n",
    "        # if using pretrained weights, Images should be renormalized according to pytorch's specification:\n",
    "        #    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "        #                                     std=[0.229, 0.224, 0.225])\n",
    "        # see https://gitlab.us.lmco.com/overwatch/cognitive-modules/classification/-/blob/master/examples/jupyter_notebooks/supervised_examples/deep_learning_examples/inception_v3_classifier_example.ipynb\n",
    "        #         Create Classes and Labels from Dataset\n",
    "\n",
    "\n",
    "\n",
    "    # train the model!\n",
    "    results = unet_model.fit(train_dataset)\n",
    "\n",
    "    # save the trained model for the epochs configured**********THIS IS WHERE I STOPPED********** Not sure if saving correctly\n",
    "    model_save_path = unet_model.save(results)\n",
    "\n",
    "    \n",
    "    ###STEP 4\n",
    "    # load the trained model\n",
    "    unet_model.load_model(model_save_path)\n",
    "\n",
    "    # load a test example\n",
    "    img, mask = test_dataset[ random.randint(0, len(test_dataset)) ]\n",
    "\n",
    "    # run model inference\n",
    "    results = model.infer([img])\n",
    "\n",
    "    result_mask = results[0]['masks']\n",
    "\n",
    "    result_mask = (result_mask - result_mask.min()) / (result_mask.max()-result_mask.min())  \n",
    "\n",
    "\n",
    "    print(\"******** Inference Results ********\")\n",
    "    print(f\"Overall minimum prediction confidence = {result_mask.min()}\")\n",
    "    print(f\"Overall maximum prediction confidence = {result_mask.max()}\")\n",
    "    print(f\"Overall mean prediction confidence = {result_mask.mean()} \\n\")\n",
    "\n",
    "    print(f\"Minimum Building prediction confidence = {result_mask[1,:,:].min()}\")\n",
    "    print(f\"Maximum Building prediction confidence = {result_mask[1,:,:].max()}\")\n",
    "    print(f\"Mean Building prediction confidence = {result_mask[1,:,:].mean()} \\n\")\n",
    "\n",
    "    print(f\"Minimum Background prediction confidence = {result_mask[0,:,:].min()}\")\n",
    "    print(f\"Maximum Background prediction confidence = {result_mask[0,:,:].max()}\")\n",
    "    print(f\"Mean Background prediction confidence = {result_mask[0,:,:].mean()}\")\n",
    "\n",
    "\n",
    "predict_op = comp.func_to_container_op(\n",
    "    predict,\n",
    "    base_image=\"harbor.ai.us.lmco.com/ai-factory-local/pytorch:1.8.1-cuda11.1-cudnn8-runtime-4\",\n",
    "    packages_to_install=['urllib3==1.25.8','fiona','numpy','Pillow','geojson', 'rioxarray', 'lm-ai-classification', 'matplotlib', 'sklearn']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name=PIPELINE_NAME,\n",
    "    description=EXPERIMENT_NAME\n",
    ")\n",
    "def rms_et_basic_pipeline():\n",
    "    view_data_r = (\n",
    "        view_data_op()\n",
    "        .add_pvolumes({\"/data\": dsl.PipelineVolume(pvc=\"spacenet-data\")})\n",
    "    )\n",
    "    predict_r = (\n",
    "        predict_op()\n",
    "        .set_gpu_limit(8)\n",
    "        .add_env_variable(k8s_client_helper.env_from_secret(\"PIP_EXTRA_INDEX_URL\", \"nexus-config\", \"PIP_EXTRA_INDEX_URL\"))\n",
    "        .add_env_variable(k8s_client_helper.env_from_secret(\"PIP_INDEX_URL\", \"nexus-config\", \"PIP_INDEX_URL\"))\n",
    "        .add_pvolumes({\"/data\": dsl.PipelineVolume(pvc=\"spacenet-data\")})\n",
    "        .after(view_data_r)\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"https://kubeflow.apps.pcell.ai.us.lmco.com/pipeline/#/runs/details/32fb6456-0a26-485e-9473-d44376e19166\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'created_at': datetime.datetime(2022, 8, 1, 12, 42, 46, tzinfo=tzlocal()),\n",
       " 'description': None,\n",
       " 'error': None,\n",
       " 'finished_at': datetime.datetime(1970, 1, 1, 0, 0, tzinfo=tzlocal()),\n",
       " 'id': '32fb6456-0a26-485e-9473-d44376e19166',\n",
       " 'metrics': None,\n",
       " 'name': 'tf_spacenet_cv_classify_pipeline-e429392 2022-08-01T12:42:46.446735',\n",
       " 'pipeline_spec': {'parameters': None,\n",
       "                   'pipeline_id': '3e8f93a7-cc76-4616-b136-c3f824fc4731',\n",
       "                   'pipeline_manifest': None,\n",
       "                   'pipeline_name': 'tf_spacenet_cv_classify_pipeline-e429392',\n",
       "                   'runtime_config': None,\n",
       "                   'workflow_manifest': '{\"kind\":\"PipelineRun\",\"apiVersion\":\"tekton.dev/v1beta1\",\"metadata\":{\"name\":\"tf-spacenet-cv-classify-pipeline-e429392\",\"creationTimestamp\":null,\"annotations\":{\"pipelines.kubeflow.org/big_data_passing_format\":\"$(workspaces.$TASK_NAME.path)/artifacts/$ORIG_PR_NAME/$TASKRUN_NAME/$TASK_PARAM_NAME\",\"pipelines.kubeflow.org/pipeline_spec\":\"{\\\\\"description\\\\\": '\n",
       "                                        '\\\\\"RMS ET Intern Project\\\\\", '\n",
       "                                        '\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"tf_spacenet_cv_classify_pipeline-e429392\\\\\"}\",\"sidecar.istio.io/inject\":\"false\",\"tekton.dev/artifact_bucket\":\"mlpipeline\",\"tekton.dev/artifact_endpoint\":\"minio-service.kubeflow:9000\",\"tekton.dev/artifact_endpoint_scheme\":\"http://\",\"tekton.dev/artifact_items\":\"{\\\\\"predict\\\\\": '\n",
       "                                        '[], \\\\\"view-data\\\\\": '\n",
       "                                        '[]}\",\"tekton.dev/input_artifacts\":\"{}\",\"tekton.dev/output_artifacts\":\"{}\"}},\"spec\":{\"pipelineSpec\":{\"tasks\":[{\"name\":\"view-data\",\"taskSpec\":{\"spec\":null,\"metadata\":{\"labels\":{\"pipelines.kubeflow.org/cache_enabled\":\"true\",\"pipelines.kubeflow.org/generation\":\"\",\"pipelines.kubeflow.org/pipelinename\":\"\"},\"annotations\":{\"pipelines.kubeflow.org/component_spec_digest\":\"{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"View data\\\\\", \\\\\"outputs\\\\\": [], '\n",
       "                                        '\\\\\"version\\\\\": \\\\\"View '\n",
       "                                        'data@sha256=98af36e18dc740840e3fe7a3262a431539131cb6783e5717bc378b299ba4b323\\\\\"}\",\"tekton.dev/template\":\"\"}},\"steps\":[{\"name\":\"main\",\"image\":\"harbor.ai.us.lmco.com/ai-factory-local/internal/aws-cli:1.20.58-debian-10-r2-0\",\"command\":[\"sh\",\"-ec\",\"program_path=$(mktemp)\\\\nprintf '\n",
       "                                        '\\\\\"%s\\\\\" \\\\\"$0\\\\\" \\\\u003e '\n",
       "                                        '\\\\\"$program_path\\\\\"\\\\npython3 -u '\n",
       "                                        '\\\\\"$program_path\\\\\" \\\\\"$@\\\\\"\\\\n\",\"def '\n",
       "                                        'view_data():\\\\n    import json\\\\n    '\n",
       "                                        'import os\\\\n    import logging\\\\n    '\n",
       "                                        'DATASET_PATH = '\n",
       "                                        '\\\\\"/data/V1/sn1_AOI_1_RIO/sn1_AOI_1_RIO/sn1_AOI_1_RIO/\\\\\"\\\\n\\\\n    '\n",
       "                                        'PATH_TO_COLLECTION_FILE = '\n",
       "                                        'os.path.join(DATASET_PATH, '\n",
       "                                        \"'collection.json')\\\\n\\\\n    with \"\n",
       "                                        \"open(PATH_TO_COLLECTION_FILE, 'r') as \"\n",
       "                                        'f:\\\\n        collection_json = '\n",
       "                                        'json.load(f)\\\\n\\\\n    '\n",
       "                                        'print(f\\\\\"collection_json top level '\n",
       "                                        'keys: '\n",
       "                                        '{collection_json.keys()}\\\\\\\\n\\\\\")\\\\n    '\n",
       "                                        'print(f\\\\\"description: '\n",
       "                                        '{collection_json[\\'description\\']}\\\\\")\\\\n\\\\n    '\n",
       "                                        'def limit_string(s, '\n",
       "                                        'chars=200):\\\\n        s = '\n",
       "                                        'str(s)\\\\n        len_to_print = '\n",
       "                                        'max(min(len(s), chars), 1)\\\\n        '\n",
       "                                        'return s[0:len_to_print]\\\\n    '\n",
       "                                        '[print(f\\\\\"{k} : '\n",
       "                                        '{limit_string(collection_json[k])}\\\\\") '\n",
       "                                        'for k in '\n",
       "                                        'collection_json.keys()]\\\\n\\\\nimport '\n",
       "                                        'argparse\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='View \"\n",
       "                                        \"data', description='')\\\\n_parsed_args \"\n",
       "                                        '= '\n",
       "                                        'vars(_parser.parse_args())\\\\n\\\\n_outputs '\n",
       "                                        '= '\n",
       "                                        'view_data(**_parsed_args)\\\\n\"],\"resources\":{},\"volumeMounts\":[{\"name\":\"pvolume-e08f34d8bcb983a9b9b9689d664304a9fe46292eb114fc9f83031d4\",\"mountPath\":\"/data\"}]}],\"volumes\":[{\"name\":\"pvolume-e08f34d8bcb983a9b9b9689d664304a9fe46292eb114fc9f83031d4\",\"persistentVolumeClaim\":{\"claimName\":\"spacenet-data\"}}]},\"timeout\":\"8760h0m0s\"},{\"name\":\"predict\",\"taskSpec\":{\"spec\":null,\"metadata\":{\"labels\":{\"pipelines.kubeflow.org/cache_enabled\":\"true\",\"pipelines.kubeflow.org/generation\":\"\",\"pipelines.kubeflow.org/pipelinename\":\"\"},\"annotations\":{\"pipelines.kubeflow.org/component_spec_digest\":\"{\\\\\"name\\\\\": '\n",
       "                                        '\\\\\"Predict\\\\\", \\\\\"outputs\\\\\": [], '\n",
       "                                        '\\\\\"version\\\\\": '\n",
       "                                        '\\\\\"Predict@sha256=a7dd4fe157fd0b41b185185f0f242e222e7aa76a31f897708ac7bba963c7215e\\\\\"}\",\"tekton.dev/template\":\"\"}},\"steps\":[{\"name\":\"main\",\"image\":\"harbor.ai.us.lmco.com/ai-factory-local/pytorch:1.8.1-cuda11.1-cudnn8-runtime-4\",\"command\":[\"sh\",\"-c\",\"(PIP_DISABLE_PIP_VERSION_CHECK=1 '\n",
       "                                        'python3 -m pip install --quiet '\n",
       "                                        '--no-warn-script-location '\n",
       "                                        \"'urllib3==1.25.8' 'fiona' 'numpy' \"\n",
       "                                        \"'Pillow' 'geojson' 'rioxarray' \"\n",
       "                                        \"'lm-ai-classification' 'matplotlib' \"\n",
       "                                        \"'sklearn' || \"\n",
       "                                        'PIP_DISABLE_PIP_VERSION_CHECK=1 '\n",
       "                                        'python3 -m pip install --quiet '\n",
       "                                        '--no-warn-script-location '\n",
       "                                        \"'urllib3==1.25.8' 'fiona' 'numpy' \"\n",
       "                                        \"'Pillow' 'geojson' 'rioxarray' \"\n",
       "                                        \"'lm-ai-classification' 'matplotlib' \"\n",
       "                                        \"'sklearn' --user) \\\\u0026\\\\u0026 \"\n",
       "                                        '\\\\\"$0\\\\\" '\n",
       "                                        '\\\\\"$@\\\\\"\",\"sh\",\"-ec\",\"program_path=$(mktemp)\\\\nprintf '\n",
       "                                        '\\\\\"%s\\\\\" \\\\\"$0\\\\\" \\\\u003e '\n",
       "                                        '\\\\\"$program_path\\\\\"\\\\npython3 -u '\n",
       "                                        '\\\\\"$program_path\\\\\" \\\\\"$@\\\\\"\\\\n\",\"def '\n",
       "                                        'predict():\\\\n    import '\n",
       "                                        'datetime\\\\n    import json\\\\n    '\n",
       "                                        'import os\\\\n    import math\\\\n    '\n",
       "                                        'import random\\\\n\\\\n    # for '\n",
       "                                        'dataset\\\\n    import torch\\\\n    '\n",
       "                                        'import numpy as np\\\\n\\\\n    # Python '\n",
       "                                        'Image Library can \\\\n    # load tiffs '\n",
       "                                        'and convert to numpy arrays\\\\n    '\n",
       "                                        'from PIL import Image\\\\n    from '\n",
       "                                        'IPython.display import '\n",
       "                                        'display\\\\n\\\\n    # for mask creation '\n",
       "                                        'based on geospatial data\\\\n    import '\n",
       "                                        'fiona\\\\n    import rioxarray\\\\n    '\n",
       "                                        'import geojson\\\\n\\\\n    from pathlib '\n",
       "                                        'import Path\\\\n    # import UNet Model '\n",
       "                                        'Configuration, UNet Vision Model '\n",
       "                                        'Configuration, and the Vision '\n",
       "                                        'Model\\\\n    import classification as '\n",
       "                                        'lmclassification\\\\n    from '\n",
       "                                        'classification.data_types.network_callbacks.checkpoint_callback '\n",
       "                                        'import CheckPointCallback as '\n",
       "                                        'CheckpointCallback\\\\n    from '\n",
       "                                        'classification.network_models.configurations.unet_model_configuration '\n",
       "                                        'import UNetModelConfiguration as '\n",
       "                                        'ModelConfiguration\\\\n    from '\n",
       "                                        'classification.vision.models.configurations.unet_vision_model_configuration '\n",
       "                                        'import UNetVisionModelConfiguration '\n",
       "                                        'as VisionModelConfiguration\\\\n    '\n",
       "                                        'from '\n",
       "                                        'classification.vision.models.unet_vision_model '\n",
       "                                        'import UNetVisionModel as '\n",
       "                                        'Model\\\\n\\\\n    import '\n",
       "                                        'matplotlib.pyplot as plt\\\\n    import '\n",
       "                                        'matplotlib.patches as patches\\\\n    '\n",
       "                                        'import matplotlib.colors as '\n",
       "                                        'colors\\\\n\\\\n    class '\n",
       "                                        'SpaceNetDataset(torch.utils.data.Dataset):\\\\n        '\n",
       "                                        '\\\\\"\\\\\"\\\\\"\\\\n        A '\n",
       "                                        'torch.utils.data.Dataset wrapping the '\n",
       "                                        'SpaceNet Building Detection V1 '\n",
       "                                        'dataset\\\\n        '\n",
       "                                        '\\\\\"\\\\\"\\\\\"\\\\n\\\\n        def '\n",
       "                                        '__init__(self, path_to_collection, '\n",
       "                                        '*args, **kwargs):\\\\n            '\n",
       "                                        '\\\\\"\\\\\"\\\\\"\\\\n            Construct the '\n",
       "                                        'dataset\\\\n\\\\n            Provide any '\n",
       "                                        'information required to allow '\n",
       "                                        'subsequent operation\\\\n            '\n",
       "                                        '\\\\\"\\\\\"\\\\\"\\\\n\\\\n            if not '\n",
       "                                        'isinstance(path_to_collection, '\n",
       "                                        'Path):\\\\n                '\n",
       "                                        'path_to_collection = '\n",
       "                                        'Path(path_to_collection)\\\\n\\\\n            '\n",
       "                                        'self.path_to_collection = '\n",
       "                                        'path_to_collection\\\\n            '\n",
       "                                        'self.collection_dir = '\n",
       "                                        'os.path.dirname(path_to_collection)\\\\n\\\\n            '\n",
       "                                        'with open(self.path_to_collection, '\n",
       "                                        \"'r') as f:\\\\n                \"\n",
       "                                        'self.collection = json.load(f)        '\n",
       "                                        '\\\\n\\\\n            # self.links holds '\n",
       "                                        'all the top level '\n",
       "                                        'folders\\\\n            # filter out '\n",
       "                                        'the ones that end with -labels since '\n",
       "                                        'we know \\\\n            # there will '\n",
       "                                        'be a corresponding non-labels '\n",
       "                                        'folder\\\\n            self.links = '\n",
       "                                        '[x[\\\\\"href\\\\\"] for x in '\n",
       "                                        'self.collection[\\\\\"links\\\\\"] if not '\n",
       "                                        'os.path.dirname(x[\\\\\"href\\\\\"]).endswith(\\'-labels\\') '\n",
       "                                        ']\\\\n\\\\n        def '\n",
       "                                        '__len__(self):\\\\n            '\n",
       "                                        '\\\\\"\\\\\"\\\\\"\\\\n            '\n",
       "                                        'Returns:\\\\n                The length '\n",
       "                                        'of the whole dataset to '\n",
       "                                        'load\\\\n            '\n",
       "                                        '\\\\\"\\\\\"\\\\\"\\\\n            return '\n",
       "                                        'len(self.links)\\\\n\\\\n        def '\n",
       "                                        '__getitem__(self, idx):        '\n",
       "                                        '\\\\n            '\n",
       "                                        '\\\\\"\\\\\"\\\\\"\\\\n            Given an '\n",
       "                                        'index, provide the training example '\n",
       "                                        'at that index\\\\n\\\\n            To '\n",
       "                                        'satisfy the CCM return a tuple of 2 '\n",
       "                                        'elements:\\\\n                The first '\n",
       "                                        'element is a numpy np.ndarray, 32-bit '\n",
       "                                        'or 64-bit float, with shape '\n",
       "                                        '(channels, pixel height, pixel '\n",
       "                                        'width)\\\\n                The second '\n",
       "                                        'element is a '\n",
       "                                        'dictionary.\\\\n                    The '\n",
       "                                        'only required key is '\n",
       "                                        \"'masks'\\\\n                    The \"\n",
       "                                        \"'masks' key must map to a numpy \"\n",
       "                                        'np.ndarray, 64-bit integers, with '\n",
       "                                        'shape (classes, pixel height, pixel '\n",
       "                                        'width)\\\\n                    In this '\n",
       "                                        'case the classes are background and '\n",
       "                                        'building (just 2 '\n",
       "                                        'classes)\\\\n                    For '\n",
       "                                        'the background class, pixel locations '\n",
       "                                        'that are background should be set to '\n",
       "                                        '1, otherwise 0\\\\n                    '\n",
       "                                        'For the building class, pixel '\n",
       "                                        'locations that are buildings should '\n",
       "                                        'be set to 1, otherwise '\n",
       "                                        '0\\\\n                    Image values '\n",
       "                                        'in the numpy ndarray should be '\n",
       "                                        'normalized to a range from 0.0 to '\n",
       "                                        '1.0\\\\n\\\\n            Other '\n",
       "                                        'requirements:\\\\n                Image '\n",
       "                                        'Width must be the same as '\n",
       "                                        'Segmentation Mask '\n",
       "                                        'Width\\\\n                Image Height '\n",
       "                                        'must be the same as Segmentation Mask '\n",
       "                                        'Height\\\\n\\\\n                If no '\n",
       "                                        'features are present. the mask should '\n",
       "                                        'still exist but take on default '\n",
       "                                        'values, eg\\\\n                    '\n",
       "                                        'background class all '\n",
       "                                        'ones\\\\n                    building '\n",
       "                                        'class all zeros\\\\n                    '\n",
       "                                        'other constraints are still '\n",
       "                                        'enforced\\\\n\\\\n            '\n",
       "                                        'Args:\\\\n                index into '\n",
       "                                        'the dataset to '\n",
       "                                        'sample\\\\n\\\\n            '\n",
       "                                        'Returns:\\\\n                The '\n",
       "                                        'dataset example at a given index in '\n",
       "                                        'the form of a tuple '\n",
       "                                        'of\\\\n                np.ndarray and '\n",
       "                                        'dictionary of string key mapped to '\n",
       "                                        'np.ndarrays\\\\n            '\n",
       "                                        '\\\\\"\\\\\"\\\\\"\\\\n\\\\n            # index '\n",
       "                                        'into folders (in the indexed folder '\n",
       "                                        'with main files)\\\\n            folder '\n",
       "                                        '= self.links[idx]\\\\n\\\\n            # '\n",
       "                                        'construct the known corresponding '\n",
       "                                        'label folder name (will look like '\n",
       "                                        \"'sn1_AOI_1_RIO_img1033-labels')\\\\n            \"\n",
       "                                        'folder_name =  '\n",
       "                                        'os.path.dirname(folder)\\\\n            '\n",
       "                                        'label_folder_name = folder_name + '\n",
       "                                        \"'-labels'\\\\n\\\\n            # \"\n",
       "                                        'construct the relative path to the '\n",
       "                                        '\\\\\"stac.json file\\\\\"\\\\n            '\n",
       "                                        'folder_json_path = '\n",
       "                                        'os.path.join(folder_name, '\n",
       "                                        \"'stac.json')\\\\n            \"\n",
       "                                        'label_json_path = '\n",
       "                                        'os.path.join(label_folder_name, '\n",
       "                                        \"'stac.json')\\\\n\\\\n            # \"\n",
       "                                        'construct the path to the image file '\n",
       "                                        '-- stored in assets.RGB. in stac.json '\n",
       "                                        '(img)\\\\n            #img_path = '\n",
       "                                        'os.path.join(json_path, '\n",
       "                                        \"'assets.RGB')\\\\n            test = \"\n",
       "                                        'os.path.join(DATASET_PATH, '\n",
       "                                        'folder_json_path)\\\\n            with '\n",
       "                                        \"open(test, 'r') as \"\n",
       "                                        'igj:\\\\n                data = '\n",
       "                                        'json.load(igj)            '\n",
       "                                        '\\\\n            img_name = '\n",
       "                                        'data[\\\\\"assets\\\\\"][\\\\\"RGB\\\\\"][\\\\\"href\\\\\"]\\\\n            '\n",
       "                                        'img_path = os.path.join(DATASET_PATH, '\n",
       "                                        'folder_name, '\n",
       "                                        'img_name)\\\\n\\\\n            # '\n",
       "                                        'construct the paths to the labels '\n",
       "                                        'file -- stored in assets.labels.href '\n",
       "                                        'in stac.json (label)\\\\n            '\n",
       "                                        'test = os.path.join(DATASET_PATH, '\n",
       "                                        'label_json_path)\\\\n            with '\n",
       "                                        \"open(test, 'r') as \"\n",
       "                                        'igj:\\\\n                data = '\n",
       "                                        'json.load(igj)            '\n",
       "                                        '\\\\n            label_name = '\n",
       "                                        'data[\\\\\"assets\\\\\"][\\\\\"labels\\\\\"][\\\\\"href\\\\\"]\\\\n            '\n",
       "                                        'label_path = '\n",
       "                                        'os.path.join(DATASET_PATH, '\n",
       "                                        'label_folder_name, '\n",
       "                                        'label_name)\\\\n\\\\n            # open '\n",
       "                                        'the .tif image from disk using '\n",
       "                                        'PIL.Image\\\\n            img = '\n",
       "                                        'Image.open(img_path)\\\\n\\\\n            '\n",
       "                                        '# convert the PIL image to a numpy '\n",
       "                                        'array - this will be '\n",
       "                                        'returned\\\\n            img_arr = '\n",
       "                                        'np.array(img, '\n",
       "                                        \"dtype='float64')\\\\n\\\\n            # \"\n",
       "                                        'normalize from 0.0 to '\n",
       "                                        '1.0\\\\n            img = '\n",
       "                                        'np.array(img_arr / '\n",
       "                                        'np.linalg.norm(img_arr))\\\\n\\\\n            '\n",
       "                                        '# open with fiona to get features for '\n",
       "                                        'mask - this represnts the '\n",
       "                                        'buildings\\\\n            with '\n",
       "                                        \"fiona.open(label_path, 'r') as \"\n",
       "                                        'f:\\\\n                features = '\n",
       "                                        '[feature[\\\\\"geometry\\\\\"] for feature '\n",
       "                                        'in f]\\\\n\\\\n            # create the '\n",
       "                                        'rasterizer object based on the image '\n",
       "                                        'data using rioxarray\\\\n            '\n",
       "                                        'rds = '\n",
       "                                        'rioxarray.open_rasterio(img_path).isel(band=0)\\\\n\\\\n            '\n",
       "                                        '# get the geojson data from the label '\n",
       "                                        'file                \\\\n            '\n",
       "                                        'with open(label_path) as '\n",
       "                                        'igj:\\\\n                data = '\n",
       "                                        'geojson.load(igj)\\\\n\\\\n            '\n",
       "                                        'print(f\\\\\"labels data = '\n",
       "                                        '{data}\\\\\")\\\\n\\\\n            # binary '\n",
       "                                        'crossentropy requires you to create '\n",
       "                                        'masks of shape (2, height, '\n",
       "                                        'width)\\\\n            # the first '\n",
       "                                        'channel represnts classes; '\n",
       "                                        '0=background, '\n",
       "                                        '1=building\\\\n            mask = '\n",
       "                                        'np.zeros((2, '\n",
       "                                        '*img.shape[0:2])).astype(np.int64)\\\\n            '\n",
       "                                        'mask[0,:,:] = np.ones((1, '\n",
       "                                        '*img.shape[0:2])) # background by '\n",
       "                                        'default\\\\n\\\\n            # now if '\n",
       "                                        'this training/validation example has '\n",
       "                                        'features (building '\n",
       "                                        'masks)\\\\n            if len(features) '\n",
       "                                        '\\\\u003e 0:\\\\n\\\\n                # get '\n",
       "                                        'the mask - binary cross '\n",
       "                                        'entropy:\\\\n                # clip the '\n",
       "                                        'image to remove the background using '\n",
       "                                        'rastersizer_object.rio.clip\\\\n                '\n",
       "                                        '# ex. rds.rio.clip(features_array, '\n",
       "                                        'geojson_data[\\\\\"crs\\\\\"][\\\\\"properties\\\\\"][\\\\\"name\\\\\"], '\n",
       "                                        'drop=False)\\\\n                rds = '\n",
       "                                        'rds.rio.clip(features, '\n",
       "                                        'data[\\\\\"crs\\\\\"][\\\\\"properties\\\\\"][\\\\\"name\\\\\"], '\n",
       "                                        'drop=False)\\\\n\\\\n                # '\n",
       "                                        'convert to np array\\\\n                '\n",
       "                                        'nprds = '\n",
       "                                        'np.array(rds)\\\\n\\\\n                # '\n",
       "                                        'search your clipped image for values '\n",
       "                                        'greater than .5\\\\n                # '\n",
       "                                        'if greater, return the corresponding '\n",
       "                                        'class (0 or 1) and store that value '\n",
       "                                        '\\\\n                # in the first '\n",
       "                                        'channel of your '\n",
       "                                        'mask\\\\n                mask[0, :, :] '\n",
       "                                        '= np.where((nprds)\\\\u003e0.5, 0, '\n",
       "                                        'mask[0, :, :])\\\\n                '\n",
       "                                        'mask[1, :, :] = '\n",
       "                                        'np.where(nprds\\\\u003e0.5, 1, mask[1, '\n",
       "                                        ':, :])\\\\n\\\\n            # if the '\n",
       "                                        'example did not have features, leave '\n",
       "                                        'the images and masks as they '\n",
       "                                        'were\\\\n            # channels, '\n",
       "                                        'height, width\\\\n\\\\n            # clip '\n",
       "                                        'both masks and images to ensure they '\n",
       "                                        'are the same size\\\\n            # '\n",
       "                                        'otherwise CCM / Most Conv networks '\n",
       "                                        'will not accept\\\\n            '\n",
       "                                        \"#print('img row:', np.size(img, \"\n",
       "                                        \"axis=0), 'img col:', np.size(img, \"\n",
       "                                        \"axis=1), 'img tall:', np.size(img, \"\n",
       "                                        \"axis=2))\\\\n            #print('img \"\n",
       "                                        \"row:', np.size(mask, axis=0), 'img \"\n",
       "                                        \"col:', np.size(mask, axis=1), 'img \"\n",
       "                                        \"tall:', np.size(mask, \"\n",
       "                                        'axis=2))\\\\n\\\\n            img = '\n",
       "                                        'np.transpose(img,(2,0,1))\\\\n            '\n",
       "                                        'min0 = min((np.size(img, '\n",
       "                                        'axis=0)),(np.size(mask, '\n",
       "                                        'axis=0)))\\\\n            min1 = '\n",
       "                                        'min((np.size(img, '\n",
       "                                        'axis=1)),(np.size(mask, '\n",
       "                                        'axis=1)))\\\\n            min2 = '\n",
       "                                        'min((np.size(img, '\n",
       "                                        'axis=2)),(np.size(mask, '\n",
       "                                        'axis=2)))           \\\\n\\\\n            '\n",
       "                                        'mask = np.resize(mask, '\n",
       "                                        '(min0,min1,min2))\\\\n            image '\n",
       "                                        '= np.resize(img, '\n",
       "                                        '(3,min1,min2))\\\\n\\\\n            '\n",
       "                                        \"#print('img row:', np.size(mask, \"\n",
       "                                        \"axis=0), 'img col:', np.size(mask, \"\n",
       "                                        \"axis=1), 'img tall:', np.size(mask, \"\n",
       "                                        \"axis=2))\\\\n            #print('img \"\n",
       "                                        \"row:', np.size(image, axis=0), 'img \"\n",
       "                                        \"col:', np.size(image, axis=1), 'img \"\n",
       "                                        \"tall:', np.size(image, \"\n",
       "                                        'axis=2))\\\\n\\\\n            # CCM '\n",
       "                                        'vision models expect targets to be in '\n",
       "                                        'a dictionary \\\\n            # other '\n",
       "                                        'keys for other types of computer '\n",
       "                                        'vision problems include\\\\n            '\n",
       "                                        \"# 'boxes' and 'labels'. UNet does not \"\n",
       "                                        'require those\\\\n            return '\n",
       "                                        \"image, {'masks': mask}\\\\n\\\\n    # \"\n",
       "                                        'Instantiate the DataLoader\\\\n    '\n",
       "                                        'DATASET_PATH = \\\\\\\\\\\\n    '\n",
       "                                        '\\\\\"\\\\\"\\\\\"/data/V1/sn1_AOI_1_RIO/sn1_AOI_1_RIO/sn1_AOI_1_RIO/\\\\\"\\\\\"\\\\\"\\\\n    '\n",
       "                                        'PATH_TO_COLLECTION_FILE=os.path.join(DATASET_PATH, '\n",
       "                                        \"'collection.json')\\\\n    dataset = \"\n",
       "                                        'SpaceNetDataset(PATH_TO_COLLECTION_FILE)\\\\n\\\\n    '\n",
       "                                        'TRAIN_SPLIT = 0.7\\\\n    TEST_SPLIT = '\n",
       "                                        '0.3\\\\n\\\\n    test_dataset, '\n",
       "                                        'train_dataset = '\n",
       "                                        'torch.utils.data.random_split(\\\\n        '\n",
       "                                        'dataset, \\\\n        '\n",
       "                                        '[math.floor(TEST_SPLIT*len(dataset)), '\n",
       "                                        'math.ceil(TRAIN_SPLIT*len(dataset)) '\n",
       "                                        '],\\\\n        '\n",
       "                                        'generator=torch.Generator().manual_seed(1234)\\\\n    '\n",
       "                                        ')\\\\n\\\\n    # instantiate UNet Model '\n",
       "                                        'Configuration\\\\n    layers_config = '\n",
       "                                        'ModelConfiguration()\\\\n\\\\n    # '\n",
       "                                        'instantiate UNet Vision Model '\n",
       "                                        'Configuration    \\\\n    # ensure we '\n",
       "                                        'allow for the background class and '\n",
       "                                        'building class RGB #input_channels = '\n",
       "                                        '3 is addition from QA\\\\n    #Answer '\n",
       "                                        'below found in '\n",
       "                                        'unet_vision_model_example  from '\n",
       "                                        'vision folder from link below\\\\n    '\n",
       "                                        'model_config = '\n",
       "                                        'VisionModelConfiguration(input_shape=(480, '\n",
       "                                        '480), n_classes=4, input_channels=3, '\n",
       "                                        'layers_model_configuration=layers_config,\\\\n                                            '\n",
       "                                        'training_epochs=2, '\n",
       "                                        'validation_split=0.0, '\n",
       "                                        'learning_rate=0.0001, '\n",
       "                                        'batch_size=5)\\\\n\\\\n    # during '\n",
       "                                        'testing x% of the training dataset '\n",
       "                                        'will be reserved for '\n",
       "                                        'validation\\\\n\\\\n    # Instantiate '\n",
       "                                        'UNet\\\\n    unet_model = '\n",
       "                                        'Model(model_config)\\\\n        # if '\n",
       "                                        'using pretrained weights, Images '\n",
       "                                        'should be renormalized according to '\n",
       "                                        \"pytorch's specification:\\\\n        \"\n",
       "                                        '#    '\n",
       "                                        'torchvision.transforms.Normalize(mean=[0.485, '\n",
       "                                        '0.456, 0.406],\\\\n        '\n",
       "                                        '#                                     '\n",
       "                                        'std=[0.229, 0.224, 0.225])\\\\n        '\n",
       "                                        '# see '\n",
       "                                        'https://gitlab.us.lmco.com/overwatch/cognitive-modules/classification/-/blob/master/examples/jupyter_notebooks/supervised_examples/deep_learning_examples/inception_v3_classifier_example.ipynb\\\\n        '\n",
       "                                        '#         Create Classes and Labels '\n",
       "                                        'from Dataset\\\\n\\\\n    # train the '\n",
       "                                        'model!\\\\n    results = '\n",
       "                                        'unet_model.fit(train_dataset)\\\\n\\\\n    '\n",
       "                                        '# save the trained model for the '\n",
       "                                        'epochs configured**********THIS IS '\n",
       "                                        'WHERE I STOPPED********** Not sure if '\n",
       "                                        'saving correctly\\\\n    '\n",
       "                                        'model_save_path = '\n",
       "                                        'unet_model.save(results)\\\\n\\\\n    '\n",
       "                                        '###STEP 4\\\\n    # load the trained '\n",
       "                                        'model\\\\n    '\n",
       "                                        'unet_model.load_model(model_save_path)\\\\n\\\\n    '\n",
       "                                        '# load a test example\\\\n    img, mask '\n",
       "                                        '= test_dataset[ random.randint(0, '\n",
       "                                        'len(test_dataset)) ]\\\\n\\\\n    # run '\n",
       "                                        'model inference\\\\n    results = '\n",
       "                                        'model.infer([img])\\\\n\\\\n    '\n",
       "                                        'result_mask = '\n",
       "                                        \"results[0]['masks']\\\\n\\\\n    \"\n",
       "                                        'result_mask = (result_mask - '\n",
       "                                        'result_mask.min()) / '\n",
       "                                        '(result_mask.max()-result_mask.min())  '\n",
       "                                        '\\\\n\\\\n    print(\\\\\"******** Inference '\n",
       "                                        'Results ********\\\\\")\\\\n    '\n",
       "                                        'print(f\\\\\"Overall minimum prediction '\n",
       "                                        'confidence = '\n",
       "                                        '{result_mask.min()}\\\\\")\\\\n    '\n",
       "                                        'print(f\\\\\"Overall maximum prediction '\n",
       "                                        'confidence = '\n",
       "                                        '{result_mask.max()}\\\\\")\\\\n    '\n",
       "                                        'print(f\\\\\"Overall mean prediction '\n",
       "                                        'confidence = {result_mask.mean()} '\n",
       "                                        '\\\\\\\\n\\\\\")\\\\n\\\\n    print(f\\\\\"Minimum '\n",
       "                                        'Building prediction confidence = '\n",
       "                                        '{result_mask[1,:,:].min()}\\\\\")\\\\n    '\n",
       "                                        'print(f\\\\\"Maximum Building prediction '\n",
       "                                        'confidence = '\n",
       "                                        '{result_mask[1,:,:].max()}\\\\\")\\\\n    '\n",
       "                                        'print(f\\\\\"Mean Building prediction '\n",
       "                                        'confidence = '\n",
       "                                        '{result_mask[1,:,:].mean()} '\n",
       "                                        '\\\\\\\\n\\\\\")\\\\n\\\\n    print(f\\\\\"Minimum '\n",
       "                                        'Background prediction confidence = '\n",
       "                                        '{result_mask[0,:,:].min()}\\\\\")\\\\n    '\n",
       "                                        'print(f\\\\\"Maximum Background '\n",
       "                                        'prediction confidence = '\n",
       "                                        '{result_mask[0,:,:].max()}\\\\\")\\\\n    '\n",
       "                                        'print(f\\\\\"Mean Background prediction '\n",
       "                                        'confidence = '\n",
       "                                        '{result_mask[0,:,:].mean()}\\\\\")\\\\n\\\\nimport '\n",
       "                                        'argparse\\\\n_parser = '\n",
       "                                        \"argparse.ArgumentParser(prog='Predict', \"\n",
       "                                        \"description='')\\\\n_parsed_args = \"\n",
       "                                        'vars(_parser.parse_args())\\\\n\\\\n_outputs '\n",
       "                                        '= '\n",
       "                                        'predict(**_parsed_args)\\\\n\"],\"env\":[{\"name\":\"PIP_EXTRA_INDEX_URL\",\"valueFrom\":{\"secretKeyRef\":{\"name\":\"nexus-config\",\"key\":\"PIP_EXTRA_INDEX_URL\"}}},{\"name\":\"PIP_INDEX_URL\",\"valueFrom\":{\"secretKeyRef\":{\"name\":\"nexus-config\",\"key\":\"PIP_INDEX_URL\"}}}],\"resources\":{\"limits\":{\"nvidia.com/gpu\":\"8\"}},\"volumeMounts\":[{\"name\":\"pvolume-e08f34d8bcb983a9b9b9689d664304a9fe46292eb114fc9f83031d4\",\"mountPath\":\"/data\"}]}],\"volumes\":[{\"name\":\"pvolume-e08f34d8bcb983a9b9b9689d664304a9fe46292eb114fc9f83031d4\",\"persistentVolumeClaim\":{\"claimName\":\"spacenet-data\"}}]},\"runAfter\":[\"view-data\"],\"timeout\":\"8760h0m0s\"}]},\"timeout\":\"8760h0m0s\"},\"status\":{}}'},\n",
       " 'resource_references': [{'key': {'id': 'f9123b6f-0d58-4928-bd62-82771168d419',\n",
       "                                  'type': 'EXPERIMENT'},\n",
       "                          'name': 'RMS ET Intern Project',\n",
       "                          'relationship': 'OWNER'},\n",
       "                         {'key': {'id': 'bea3ccad-bb6f-4ef4-97c7-7a57076ca381',\n",
       "                                  'type': 'PIPELINE_VERSION'},\n",
       "                          'name': 'tf_spacenet_cv_classify_pipeline-e429392_version_at_2022-08-01T12:42:46.446735Z',\n",
       "                          'relationship': 'CREATOR'}],\n",
       " 'scheduled_at': datetime.datetime(1970, 1, 1, 0, 0, tzinfo=tzlocal()),\n",
       " 'service_account': 'default-editor',\n",
       " 'status': None,\n",
       " 'storage_state': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = kfp_tekton.TektonClient(\n",
    "    host=f\"{KUBEFLOW_PUBLIC_ENDPOINT_URL}/pipeline\",\n",
    "    ssl_ca_cert=\"/etc/ssl/certs/ca-certificates.crt\",\n",
    "    cookies=SESSION_COOKIE\n",
    ")\n",
    "\n",
    "try:\n",
    "    experiment = client.get_experiment(experiment_name=EXPERIMENT_NAME)\n",
    "except ValueError:\n",
    "    experiment = client.create_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "\n",
    "kfp_tekton.compiler._op_to_template.RESOURCE_OP_IMAGE='lmregistry.us.lmco.com/ext.hub.docker.com/aipipeline/kubectl-wrapper:0.8.0'\n",
    "kfp_tekton.compiler.TektonCompiler().compile(rms_et_basic_pipeline, PIPELINE_PACKAGE)\n",
    "\n",
    "\n",
    "pipeline_id = client.get_pipeline_id(PIPELINE_NAME)\n",
    "\n",
    "if not pipeline_id:\n",
    "    # upload the package to Kubeflow\n",
    "    r = client.upload_pipeline(PIPELINE_PACKAGE, pipeline_name=PIPELINE_NAME)\n",
    "\n",
    "    # update the pipeline id\n",
    "    pipeline_id = r.id\n",
    "\n",
    "now = datetime.datetime.now().isoformat()\n",
    "pipeline_versionName = f\"{PIPELINE_NAME}_version_at_{now}Z\"\n",
    "version = client.pipeline_uploads.upload_pipeline_version(uploadfile=PIPELINE_PACKAGE, name=pipeline_versionName, pipelineid=pipeline_id)\n",
    "\n",
    "client.run_pipeline(experiment.id, f\"{PIPELINE_NAME} {now}\", pipeline_id=pipeline_id, version_id=version.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
